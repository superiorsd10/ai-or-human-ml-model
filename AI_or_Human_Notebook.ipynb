{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-26T14:03:48.319098Z","iopub.status.busy":"2024-05-26T14:03:48.318660Z","iopub.status.idle":"2024-05-26T14:04:50.525988Z","shell.execute_reply":"2024-05-26T14:04:50.524662Z","shell.execute_reply.started":"2024-05-26T14:03:48.319062Z"},"id":"FmL7OeTmS4My","outputId":"a3a4cb34-4fd4-4243-a8fb-ad50876ebecd","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from nltk.corpus import stopwords\n","from nltk import word_tokenize, FreqDist\n","import spacy\n","import string\n","import re\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","import textstat\n","from gensim import corpora, models\n","from nltk.lm import MLE\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","from nltk.util import ngrams\n","from scipy.sparse import hstack"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-26T14:05:25.337964Z","iopub.status.busy":"2024-05-26T14:05:25.337298Z","iopub.status.idle":"2024-05-26T14:05:51.690923Z","shell.execute_reply":"2024-05-26T14:05:51.689407Z","shell.execute_reply.started":"2024-05-26T14:05:25.337909Z"},"id":"zPf79zouS_39","outputId":"b884cf57-cd12-4f02-f0f0-3bcccd90ed52","trusted":true},"outputs":[],"source":["# data Preparation\n","\n","text_data = pd.read_csv(\"ai-or-human-ml-model/AI_Human_random_10k.csv\")\n","\n","human_data = text_data[text_data[\"generated\"] == 0].sample(500)\n","ai_data = text_data[text_data[\"generated\"] == 1].sample(500)\n","\n","text_data = pd.concat([human_data, ai_data])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-26T14:05:59.283626Z","iopub.status.busy":"2024-05-26T14:05:59.283185Z","iopub.status.idle":"2024-05-26T14:05:59.531192Z","shell.execute_reply":"2024-05-26T14:05:59.529896Z","shell.execute_reply.started":"2024-05-26T14:05:59.283591Z"},"id":"9xsG8QIXTLOx","outputId":"160955a6-f233-406a-ff1a-b4cb59530452","trusted":true},"outputs":[],"source":["# download stop words & define punctuation\n","\n","import nltk\n","\n","nltk.download(\"stopwords\")\n","stop_words = set(stopwords.words(\"english\"))\n","punctuations = string.punctuation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-26T14:06:03.071016Z","iopub.status.busy":"2024-05-26T14:06:03.070547Z","iopub.status.idle":"2024-05-26T14:06:06.781346Z","shell.execute_reply":"2024-05-26T14:06:06.779964Z","shell.execute_reply.started":"2024-05-26T14:06:03.070980Z"},"id":"mLk0drUzTOT5","outputId":"f0de1e04-6b4f-4bd5-b0b5-c16cefb7fac7","trusted":true},"outputs":[],"source":["# text preprocessing\n","\n","nltk.download(\"punkt\")\n","\n","\n","def preprocess_text(text):\n","    text = text.lower()\n","    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n","\n","    tokens = word_tokenize(text)\n","    filtered_tokens = [\n","        token\n","        for token in tokens\n","        if token not in stop_words and token not in punctuations\n","    ]\n","\n","    preprocessed_text = \" \".join(filtered_tokens)\n","\n","    return preprocessed_text\n","\n","\n","text_data[\"text\"] = text_data[\"text\"].apply(preprocess_text)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T14:06:11.667299Z","iopub.status.busy":"2024-05-26T14:06:11.666421Z","iopub.status.idle":"2024-05-26T14:06:13.113055Z","shell.execute_reply":"2024-05-26T14:06:13.111836Z","shell.execute_reply.started":"2024-05-26T14:06:11.667260Z"},"id":"X75fvWjDUMtF","trusted":true},"outputs":[],"source":["nlp = spacy.load(\"en_core_web_sm\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T14:06:15.882358Z","iopub.status.busy":"2024-05-26T14:06:15.881889Z","iopub.status.idle":"2024-05-26T14:06:15.896371Z","shell.execute_reply":"2024-05-26T14:06:15.894949Z","shell.execute_reply.started":"2024-05-26T14:06:15.882324Z"},"id":"eznnZ5kXUPfO","trusted":true},"outputs":[],"source":["# feature extraction (linguistic features)\n","\n","\n","def extract_linguistic_features(text, label):\n","    doc = nlp(text)\n","    features = {}\n","\n","    # lexical features\n","    features[\"word_count\"] = len([token for token in doc if not token.is_punct])\n","    features[\"unique_word_count\"] = len(\n","        set([token.text for token in doc if not token.is_punct])\n","    )\n","    features[\"ttr\"] = (\n","        features[\"unique_word_count\"] / features[\"word_count\"]\n","        if features[\"word_count\"] > 0\n","        else 0\n","    )\n","    features[\"noun_count\"] = len([token for token in doc if token.pos_ == \"NOUN\"])\n","    features[\"verb_count\"] = len([token for token in doc if token.pos_ == \"VERB\"])\n","    features[\"adj_count\"] = len([token for token in doc if token.pos_ == \"ADJ\"])\n","\n","    # syntactic features\n","    features[\"avg_sent_len\"] = np.mean([len(sent) for sent in doc.sents])\n","    features[\"max_sent_len\"] = max([len(sent) for sent in doc.sents], default=0)\n","    features[\"min_sent_len\"] = min([len(sent) for sent in doc.sents], default=0)\n","    features[\"passive_voice_count\"] = len(\n","        [token for token in doc if token.dep_ == \"auxpass\"]\n","    )\n","\n","    # discourse & rhetorical features\n","    features[\"entity_count\"] = len(doc.ents)\n","    features[\"conjunction_count\"] = len(\n","        [token for token in doc if token.pos_ == \"CCONJ\"]\n","    )\n","\n","    # stylistic features\n","    features[\"contraction_count\"] = len(\n","        [\n","            token\n","            for token in doc\n","            if token.text in [\"n't\", \"'s\", \"'d\", \"'ll\", \"'re\", \"'ve\"]\n","        ]\n","    )\n","    features[\"punctuation_count\"] = len([token for token in doc if token.is_punct])\n","\n","    return features, label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-26T14:06:20.067532Z","iopub.status.busy":"2024-05-26T14:06:20.067087Z","iopub.status.idle":"2024-05-26T14:06:57.236994Z","shell.execute_reply":"2024-05-26T14:06:57.235458Z","shell.execute_reply.started":"2024-05-26T14:06:20.067497Z"},"id":"gn-O1VNXUS_s","outputId":"f74c98e1-a4c1-40a5-8100-973202c6865a","trusted":true},"outputs":[],"source":["# initialize the language model\n","\n","corpus = text_data[\"text\"].tolist()\n","train_data = [list(doc.split()) for doc in corpus]\n","train_data, padded_sents = padded_everygram_pipeline(2, train_data)\n","language_model = MLE(2)\n","language_model.fit(train_data, padded_sents)\n","\n","# perplexity calculation\n","\n","\n","def calculate_perplexity(text):\n","    if text.split():\n","        perplexity = language_model.perplexity(text.split())\n","        return perplexity\n","    return 0\n","\n","\n","# sentiment analysis\n","\n","\n","def analyze_sentiment(text):\n","    analyzer = SentimentIntensityAnalyzer()\n","    sentiment_scores = analyzer.polarity_scores(text)\n","    return sentiment_scores\n","\n","\n","# n-gram frequency distribution\n","\n","\n","def get_ngram_freq_dist(text, n):\n","    tokens = word_tokenize(text)\n","    ngrams_list = list(ngrams(tokens, n))\n","    freq_dist = FreqDist(ngrams_list)\n","    return freq_dist"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T14:09:09.617071Z","iopub.status.busy":"2024-05-26T14:09:09.616592Z","iopub.status.idle":"2024-05-26T14:09:09.631206Z","shell.execute_reply":"2024-05-26T14:09:09.629864Z","shell.execute_reply.started":"2024-05-26T14:09:09.617035Z"},"id":"pGFwMxzoU6sD","trusted":true},"outputs":[],"source":["# feature extraction (additional features)\n","\n","\n","def extract_additional_features(text, label):\n","    features = {}\n","\n","    # perplexity\n","    perplexity = calculate_perplexity(text)\n","    features[\"perplexity\"] = perplexity\n","\n","    # readability scores\n","\n","    if text.strip():\n","        features[\"flesch_reading_ease\"] = textstat.flesch_reading_ease(text)\n","        features[\"smog_index\"] = textstat.smog_index(text)\n","    else:\n","        features[\"flesch_reading_ease\"] = 0\n","        features[\"smog_index\"] = 0\n","\n","    # sentiment and emotion analysis\n","\n","    sentiment_scores = analyze_sentiment(text)\n","    features[\"sentiment_scores\"] = sentiment_scores\n","\n","    # named entity recognition\n","\n","    doc = nlp(text)\n","    features[\"person_count\"] = len([ent for ent in doc.ents if ent.label_ == \"PERSON\"])\n","    features[\"org_count\"] = len([ent for ent in doc.ents if ent.label_ == \"ORG\"])\n","    features[\"loc_count\"] = len([ent for ent in doc.ents if ent.label_ == \"LOC\"])\n","\n","    # topic modeling\n","    if text.strip():\n","        dictionary = corpora.Dictionary([text.split()])\n","        corpus = [dictionary.doc2bow(text.split())]\n","        lda_model = models.LdaMulticore(\n","            corpus=corpus, id2word=dictionary, num_topics=10\n","        )\n","        topic_distribution = lda_model.get_document_topics(corpus[0])\n","        features[\"topic_distribution\"] = topic_distribution\n","    else:\n","        features[\"topic_distribution\"] = []\n","\n","    # n-gram distributions\n","    features[\"bigram_freq_dist\"] = get_ngram_freq_dist(text, 2)\n","    features[\"trigram_freq_dist\"] = get_ngram_freq_dist(text, 3)\n","\n","    return features, label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2024-05-26T14:09:14.828741Z","iopub.status.busy":"2024-05-26T14:09:14.828280Z","iopub.status.idle":"2024-05-26T14:13:54.947944Z","shell.execute_reply":"2024-05-26T14:13:54.946324Z","shell.execute_reply.started":"2024-05-26T14:09:14.828705Z"},"id":"wKiBFriEVFni","outputId":"a0033a0c-38b6-4f11-b992-1f9cf222d6fe","trusted":true},"outputs":[],"source":["# extract features for text data\n","\n","text_features = []\n","text_labels = []\n","additional_text_features = []\n","additional_text_labels = []\n","text_data = text_data[text_data[\"text\"].str.len() > 0]\n","\n","for text, label in zip(text_data[\"text\"], text_data[\"generated\"]):\n","    features, label = extract_linguistic_features(text, label)\n","    additional_features, label = extract_additional_features(text, label)\n","    text_features.append(features)\n","    text_labels.append(label)\n","    additional_text_features.append(additional_features)\n","    additional_text_labels.append(label)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T14:14:05.317475Z","iopub.status.busy":"2024-05-26T14:14:05.317040Z","iopub.status.idle":"2024-05-26T14:14:05.748100Z","shell.execute_reply":"2024-05-26T14:14:05.746102Z","shell.execute_reply.started":"2024-05-26T14:14:05.317437Z"},"trusted":true},"outputs":[],"source":["# features vectorization & combining them\n","\n","text_vectorizer = TfidfVectorizer()\n","text_tfidf = text_vectorizer.fit_transform([str(d) for d in text_features])\n","\n","additional_vectorizer = TfidfVectorizer()\n","additional_tfidf = additional_vectorizer.fit_transform(\n","    [str(d) for d in additional_text_features]\n",")\n","\n","X_text = hstack((text_tfidf, additional_tfidf))"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T14:14:47.204908Z","iopub.status.busy":"2024-05-26T14:14:47.204347Z","iopub.status.idle":"2024-05-26T14:14:47.214916Z","shell.execute_reply":"2024-05-26T14:14:47.213537Z","shell.execute_reply.started":"2024-05-26T14:14:47.204868Z"},"trusted":true},"outputs":[],"source":["# data splitting\n","\n","X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(\n","    X_text, text_labels, test_size=0.2, random_state=42\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T14:15:06.076808Z","iopub.status.busy":"2024-05-26T14:15:06.076319Z","iopub.status.idle":"2024-05-26T14:28:24.855599Z","shell.execute_reply":"2024-05-26T14:28:24.854051Z","shell.execute_reply.started":"2024-05-26T14:15:06.076770Z"},"trusted":true},"outputs":[],"source":["# ensemble learning & hypertuning\n","\n","voting_classifier = VotingClassifier(\n","    estimators=[\n","        (\"rf\", RandomForestClassifier()),\n","        (\"lr\", LogisticRegression()),\n","        (\"svc\", SVC(probability=True)),\n","    ],\n","    voting=\"soft\",\n",")\n","\n","# hyperparameter tuning\n","param_grid = {\n","    \"rf__n_estimators\": [100, 200, 500],\n","    \"rf__max_depth\": [None, 10, 20],\n","    \"lr__C\": [0.1, 1, 10],\n","    \"svc__C\": [0.1, 1, 10],\n","    \"svc__gamma\": [\"auto\", \"scale\"],\n","}\n","\n","grid_search = GridSearchCV(\n","    voting_classifier, param_grid, cv=5, scoring=\"f1\", verbose=1, n_jobs=-1\n",")\n","grid_search.fit(X_train_text, y_train_text)\n","\n","# evaluate best model\n","best_model = grid_search.best_estimator_\n","y_pred = best_model.predict(X_test_text)\n","accuracy = accuracy_score(y_test_text, y_pred)\n","precision = precision_score(y_test_text, y_pred)\n","recall = recall_score(y_test_text, y_pred)\n","f1 = f1_score(y_test_text, y_pred)\n","\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1-score: {f1:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T16:39:59.039246Z","iopub.status.busy":"2024-05-26T16:39:59.038820Z","iopub.status.idle":"2024-05-26T16:39:59.338026Z","shell.execute_reply":"2024-05-26T16:39:59.336548Z","shell.execute_reply.started":"2024-05-26T16:39:59.039213Z"},"trusted":true},"outputs":[],"source":["# function to predict if text is human or AI-generated\n","\n","\n","def predict_text_authorship(input_text, model, vectorizers):\n","    input_text_features = extract_linguistic_features(input_text, 0)[0]\n","    input_text_additional_features = extract_additional_features(input_text, 0)[0]\n","    input_text_features_str = str(input_text_features)\n","    input_text_additional_features_str = str(input_text_additional_features)\n","    input_text_tfidf = hstack(\n","        (\n","            vectorizers[0].transform([input_text_features_str]),\n","            vectorizers[1].transform([input_text_additional_features_str]),\n","        )\n","    )\n","    prediction = model.predict(input_text_tfidf)[0]\n","    if prediction == 0:\n","        return \"Human-generated\"\n","    else:\n","        return \"AI-generated\"\n","\n","\n","example_text = \"Education is the cornerstone of a prosperous society.\"\n","\n","print(\n","    f\"Predicted authorship: {predict_text_authorship(example_text, best_model, [text_vectorizer, additional_vectorizer])}\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T15:39:16.030783Z","iopub.status.busy":"2024-05-26T15:39:16.030256Z","iopub.status.idle":"2024-05-26T15:39:22.196385Z","shell.execute_reply":"2024-05-26T15:39:22.191727Z","shell.execute_reply.started":"2024-05-26T15:39:16.030746Z"},"trusted":true},"outputs":[],"source":["# 3. LIME (Local Interpretable Model-agnostic Explanations)\n","\n","from lime import lime_text\n","\n","\n","def preprocess_and_predict(text):\n","    if isinstance(text, str):\n","        preprocessed_text = preprocess_text(text)\n","        preprocessed_text = [preprocessed_text]\n","    else:\n","        preprocessed_text = [preprocess_text(t) for t in text]\n","\n","    text_tfidf = text_vectorizer.transform(preprocessed_text)\n","    additional_tfidf = additional_vectorizer.transform(preprocessed_text)\n","    X_text = hstack((text_tfidf, additional_tfidf))\n","\n","    proba_scores = best_model.predict_proba(X_text)\n","\n","    return proba_scores\n","\n","\n","explainer = lime_text.LimeTextExplainer(class_names=[\"Human\", \"AI\"])\n","\n","\n","idx = 0\n","raw_text = text_data[\"text\"].iloc[idx]\n","exp = explainer.explain_instance(raw_text, preprocess_and_predict, num_features=10)\n","\n","print(f\"Explanation for instance {idx}:\\n{exp.as_list()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T15:25:43.444391Z","iopub.status.busy":"2024-05-26T15:25:43.443938Z","iopub.status.idle":"2024-05-26T15:25:43.817253Z","shell.execute_reply":"2024-05-26T15:25:43.816027Z","shell.execute_reply.started":"2024-05-26T15:25:43.444358Z"},"trusted":true},"outputs":[],"source":["# confusion matrix\n","\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","conf_matrix = confusion_matrix(y_test_text, y_pred)\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(\n","    conf_matrix,\n","    annot=True,\n","    cmap=\"Blues\",\n","    xticklabels=[\"Human\", \"AI\"],\n","    yticklabels=[\"Human\", \"AI\"],\n",")\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted Labels\")\n","plt.ylabel(\"True Labels\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T15:26:38.580511Z","iopub.status.busy":"2024-05-26T15:26:38.580028Z","iopub.status.idle":"2024-05-26T15:26:38.601724Z","shell.execute_reply":"2024-05-26T15:26:38.600492Z","shell.execute_reply.started":"2024-05-26T15:26:38.580475Z"},"trusted":true},"outputs":[],"source":["# classification report\n","\n","from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test_text, y_pred, target_names=[\"Human\", \"AI\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T15:27:14.364065Z","iopub.status.busy":"2024-05-26T15:27:14.363469Z","iopub.status.idle":"2024-05-26T15:27:14.819042Z","shell.execute_reply":"2024-05-26T15:27:14.817876Z","shell.execute_reply.started":"2024-05-26T15:27:14.364023Z"},"trusted":true},"outputs":[],"source":["# ROC curve and AUC\n","from sklearn.metrics import roc_curve, auc\n","\n","fpr, tpr, thresholds = roc_curve(\n","    y_test_text, best_model.predict_proba(X_test_text)[:, 1]\n",")\n","roc_auc = auc(fpr, tpr)\n","\n","plt.figure(figsize=(8, 6))\n","plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n","plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n","plt.legend(loc=\"lower right\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T15:27:34.622671Z","iopub.status.busy":"2024-05-26T15:27:34.622033Z","iopub.status.idle":"2024-05-26T15:27:35.073007Z","shell.execute_reply":"2024-05-26T15:27:35.071622Z","shell.execute_reply.started":"2024-05-26T15:27:34.622608Z"},"trusted":true},"outputs":[],"source":["# Precision-Recall curve\n","from sklearn.metrics import precision_recall_curve\n","\n","\n","precision, recall, thresholds = precision_recall_curve(\n","    y_test_text, best_model.predict_proba(X_test_text)[:, 1]\n",")\n","\n","\n","plt.figure(figsize=(8, 6))\n","plt.plot(recall, precision, lw=2, color=\"darkgreen\", label=\"Precision-Recall Curve\")\n","plt.xlabel(\"Recall\")\n","plt.ylabel(\"Precision\")\n","plt.title(\"Precision-Recall Curve\")\n","plt.legend(loc=\"lower left\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T15:30:01.794383Z","iopub.status.busy":"2024-05-26T15:30:01.793844Z","iopub.status.idle":"2024-05-26T15:30:35.184622Z","shell.execute_reply":"2024-05-26T15:30:35.183329Z","shell.execute_reply.started":"2024-05-26T15:30:01.794347Z"},"trusted":true},"outputs":[],"source":["# cross-validation scores\n","\n","from sklearn.model_selection import cross_val_score\n","\n","cv_scores = cross_val_score(best_model, X_text, text_labels, cv=10, scoring=\"f1\")\n","\n","print(\"Cross-Validation Scores:\")\n","print(cv_scores)\n","print(f\"Mean Cross-Validation Score: {cv_scores.mean():.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T15:31:25.142522Z","iopub.status.busy":"2024-05-26T15:31:25.141992Z","iopub.status.idle":"2024-05-26T15:31:40.824899Z","shell.execute_reply":"2024-05-26T15:31:40.823421Z","shell.execute_reply.started":"2024-05-26T15:31:25.142484Z"},"trusted":true},"outputs":[],"source":["# learning curve\n","from sklearn.model_selection import learning_curve\n","\n","\n","train_sizes, train_scores, test_scores = learning_curve(\n","    best_model, X_text, text_labels, cv=5, scoring=\"f1\", n_jobs=-1\n",")\n","\n","\n","train_mean = np.mean(train_scores, axis=1)\n","train_std = np.std(train_scores, axis=1)\n","test_mean = np.mean(test_scores, axis=1)\n","test_std = np.std(test_scores, axis=1)\n","\n","\n","plt.figure(figsize=(10, 6))\n","plt.plot(train_sizes, train_mean, color=\"blue\", label=\"Training Score\")\n","plt.fill_between(\n","    train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"blue\"\n",")\n","plt.plot(train_sizes, test_mean, color=\"green\", label=\"Cross-Validation Score\")\n","plt.fill_between(\n","    train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"green\"\n",")\n","plt.xlabel(\"Number of Training Examples\")\n","plt.ylabel(\"F1-Score\")\n","plt.title(\"Learning Curve\")\n","plt.legend(loc=\"best\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T15:32:00.967331Z","iopub.status.busy":"2024-05-26T15:32:00.966885Z","iopub.status.idle":"2024-05-26T15:32:01.822049Z","shell.execute_reply":"2024-05-26T15:32:01.820808Z","shell.execute_reply.started":"2024-05-26T15:32:00.967292Z"},"trusted":true},"outputs":[],"source":["# calibration curve\n","\n","from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n","\n","\n","calibrated_model = CalibratedClassifierCV(best_model, cv=\"prefit\", method=\"isotonic\")\n","calibrated_model.fit(X_train_text, y_train_text)\n","\n","\n","fraction_of_positives, mean_predicted_value = calibration_curve(\n","    y_test_text, calibrated_model.predict_proba(X_test_text)[:, 1], n_bins=10\n",")\n","\n","\n","plt.figure(figsize=(10, 6))\n","plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Perfect Calibration\")\n","plt.plot(\n","    mean_predicted_value, fraction_of_positives, \"s-\", label=\"Calibrated Classifier\"\n",")\n","plt.xlabel(\"Mean Predicted Probability\")\n","plt.ylabel(\"Fraction of Positives\")\n","plt.title(\"Calibration Curve\")\n","plt.legend(loc=\"best\")\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4288635,"sourceId":7379779,"sourceType":"datasetVersion"}],"dockerImageVersionId":30700,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
